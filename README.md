# ğŸ›ï¸ Smart Product Pricing Challenge - Multimodal ML Solution

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/release/python-380/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c?logo=pytorch&logoColor=white)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A sophisticated multimodal deep learning solution for predicting e-commerce product prices using both textual catalog content and product images. This project implements a state-of-the-art transformer-based architecture with cross-attention mechanisms to achieve optimal pricing predictions.

## ğŸ“‹ Table of Contents

- [Problem Statement](#-problem-statement)
- [Solution Architecture](#-solution-architecture)
- [Technical Implementation](#-technical-implementation)
- [System Requirements](#-system-requirements)
- [Installation & Setup](#-installation--setup)
- [Usage Guide](#-usage-guide)
- [Project Structure](#-project-structure)
- [Dependencies](#-dependencies)

## ğŸ¯ Problem Statement

### Challenge Overview
In e-commerce, determining optimal product pricing is crucial for marketplace success and customer satisfaction. The challenge requires developing an ML solution that analyzes multimodal product data to predict accurate prices.

### Key Constraints
- **Dataset**: 75,000 training samples, 75,000 test samples
- **Evaluation Metric**: SMAPE (Symmetric Mean Absolute Percentage Error)
- **Model Limit**: â‰¤8 Billion parameters
- **License**: MIT/Apache 2.0 compliant models only
- **Strict Policy**: No external price lookup allowed

### Data Structure
```
ğŸ“Š Input Features:
â”œâ”€â”€ sample_id: Unique identifier
â”œâ”€â”€ catalog_content: Product titles, descriptions, specifications
â”œâ”€â”€ image_link: Product image URLs
â””â”€â”€ price: Target variable (training only)

ğŸ¯ Output Format:
â”œâ”€â”€ sample_id: Matching test sample IDs
â””â”€â”€ price: Predicted positive float values
```

### Evaluation Formula
```
SMAPE = (1/n) * Î£ |predicted_price - actual_price| / ((|actual_price| + |predicted_price|)/2)
```
- **Range**: 0% to 200% (lower is better)
- **Example**: Actual=$100, Predicted=$120 â†’ SMAPE=18.18%

## ğŸ—ï¸ Solution Architecture

### Multimodal Deep Learning Approach

Our solution implements a sophisticated **cross-attention multimodal architecture** that effectively combines textual and visual features for price prediction.

```
ğŸ§  Model Architecture:
â”œâ”€â”€ Text Encoder (DistilBERT)
â”‚   â”œâ”€â”€ Advanced text preprocessing
â”‚   â”œâ”€â”€ Structured information extraction
â”‚   â””â”€â”€ 768-dim embeddings
â”œâ”€â”€ Image Encoder (EfficientNet-B0)
â”‚   â”œâ”€â”€ Robust image processing
â”‚   â”œâ”€â”€ Data augmentation pipeline
â”‚   â””â”€â”€ 512-dim visual features
â”œâ”€â”€ Cross-Attention Mechanism
â”‚   â”œâ”€â”€ Multi-head attention (8 heads)
â”‚   â”œâ”€â”€ Text-to-image attention
â”‚   â””â”€â”€ Feature fusion
â””â”€â”€ Price Prediction Head
    â”œâ”€â”€ Multi-layer regression
    â”œâ”€â”€ Softplus activation
    â””â”€â”€ Positive price guarantee
```

## ğŸ”§ Technical Implementation

### Core Components

#### 1. **Text Processing Pipeline** (`data_loader.py`)
- **Advanced Text Cleaning**: Regex-based structured information extraction
- **Feature Engineering**: Item names, bullet points, specifications parsing
- **Tokenization**: DistilBERT tokenizer with 256 max length
- **Memory Optimization**: Efficient text length management

#### 2. **Image Processing Pipeline** (`data_loader.py`)
- **Robust Download System**: Retry logic with caching mechanism
- **Data Augmentation**: Albumentations-based transformations
- **Preprocessing**: ImageNet normalization and resizing
- **Cache Management**: Persistent image storage for efficiency

#### 3. **Multimodal Architecture** (`multimodal_model.py`)
```python
class MultimodalPricePredictionModel(nn.Module):
    - TextEncoder: DistilBERT + projection layers
    - ImageEncoder: EfficientNet + feature extraction
    - CrossAttention: Multi-head attention mechanism
    - FusionLayers: Feature combination and processing
    - PricePredictor: Regression head with positive constraints
```

#### 4. **Training Framework** (`train_model.py`)
- **Custom Loss Functions**: 
  - `SMAPELoss`: Direct SMAPE optimization
  - `CombinedLoss`: Weighted SMAPE + MSE for stability
- **Advanced Optimization**:
  - AdamW optimizer with weight decay
  - OneCycleLR scheduling
  - Gradient accumulation for effective larger batches
- **Training Enhancements**:
  - Mixed precision training (AMP)
  - Early stopping with patience
  - Memory management and GPU optimization

#### 5. **Prediction Pipeline** (`predict.py`)
- **Single Model Inference**: Optimized batch processing
- **Ensemble Methods**: Weighted combination of multiple models
- **Output Validation**: Format compliance and constraint checking
- **Memory Efficiency**: GPU cache management during inference

### Key Innovation Features

#### ğŸ¯ **Cross-Attention Mechanism**
```python
def forward(self, text_features, image_features):
    # Multi-head attention between text and image
    Q = self.text_to_q(text_features)  # Query from text
    K = self.image_to_k(image_features)  # Key from image
    V = self.image_to_v(image_features)  # Value from image
    
    attention_output = self.multi_head_attention(Q, K, V)
    return self.layer_norm(text_features + attention_output)
```

#### ğŸ“Š **Advanced Text Feature Engineering**
- Structured parsing of product specifications
- Bullet point extraction and prioritization
- Value-unit pair recognition
- Brand and category identification

#### ğŸ–¼ï¸ **Robust Image Processing**
- Intelligent retry mechanisms for image downloads
- Comprehensive data augmentation strategies
- EfficientNet-based feature extraction
- Fallback handling for failed downloads

## ğŸ’» System Requirements

### Development Environment
```
ğŸ–¥ï¸ Hardware Specifications:
â”œâ”€â”€ CPU: Intel Core i5-12450HX
â”œâ”€â”€ RAM: 16GB DDR5
â”œâ”€â”€ GPU: NVIDIA RTX 3050 (6GB VRAM)
â””â”€â”€ Storage: 512 GB SSD

âš™ï¸ Software Requirements:
â”œâ”€â”€ Python: 3.8 - 3.11
â”œâ”€â”€ CUDA: 11.8+ (for GPU acceleration)
â”œâ”€â”€ Operating System: Windows 10
â””â”€â”€ Available Disk Space: 40 GB+ (for datasets and models)
```

### Performance Optimizations
- **Memory Efficient**: Optimized for 6GB VRAM GPUs
- **Batch Processing**: Dynamic batch size adjustment
- **Mixed Precision**: FP16 training for 2x speed improvement
- **Gradient Accumulation**: Effective larger batch sizes without memory increase

## ğŸš€ Installation & Setup

### Step 1: Environment Setup
```bash
# Clone the repository
git clone <repository-url>
cd smart-product-pricing

# Create virtual environment
python -m venv .venv
On Windows: .venv\Scripts\activate

# Verify CUDA installation (optional but recommended)
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

### Step 2: Dataset Preparation
```
ğŸ“ Required Dataset Structure:
dataset/
â”œâ”€â”€ train.csv          # 75k training samples
â”œâ”€â”€ test.csv           # 75k test samples  
â”œâ”€â”€ sample_test.csv    # Sample test file
â””â”€â”€ sample_test_out.csv # Expected output format
```

## ğŸ“– Usage Guide

### Training the Model

#### Quick Start Training
```bash
# Run complete training pipeline
python src/run_pipeline.py
```

#### Custom Training Configuration
```python
# Modify training parameters in train_model.py
config = ModelConfig()
config.batch_size = 16          # Adjust for your GPU
config.learning_rate = 2e-5     # Fine-tune learning rate
config.num_epochs = 10          # Training duration
config.hidden_dim = 512         # Model complexity
```

### Making Predictions

#### Generate Test Predictions
```bash
# Use best trained model
python src/predict.py
```

#### Custom Prediction Script
```python
from src.predict import ModelPredictor

# Load trained model
predictor = ModelPredictor("src/model_checkpoints/best_model.pt")

# Predict on test set
results = predictor.predict_dataset("dataset/test.csv")
results.to_csv("predictions.csv", index=False)
```

### Model Evaluation
```python
# Calculate SMAPE score
from src.train_model import calculate_smape_metric

smape_score = calculate_smape_metric(y_true, y_pred)
print(f"SMAPE Score: {smape_score:.2f}%")
```

## ğŸ“ Project Structure

```
smart-product-pricing/
â”œâ”€â”€ ğŸ“„ README.md                    # Project documentation
â”œâ”€â”€ ğŸ“‚ dataset/                     # Training and test data
â”‚   â”œâ”€â”€ train.csv                   # Training dataset (75k samples)
â”‚   â”œâ”€â”€ test.csv                    # Test dataset (75k samples)
â”‚   â”œâ”€â”€ sample_test.csv             # Sample test data
â”‚   â””â”€â”€ sample_test_out.csv         # Expected output format
â”œâ”€â”€ ğŸ“‚ src/                         # Source code
â”‚   â”œâ”€â”€ ğŸ§  multimodal_model.py      # Core model architecture
â”‚   â”œâ”€â”€ ğŸ“Š data_loader.py           # Data processing pipeline
â”‚   â”œâ”€â”€ ğŸ‹ï¸ train_model.py           # Training framework
â”‚   â”œâ”€â”€ ğŸ”® predict.py               # Prediction pipeline
â”‚   â”œâ”€â”€ ğŸ”„ continue_training.py     # Advanced training
â”‚   â”œâ”€â”€ ğŸš€ run_pipeline.py          # Complete workflow
â”‚   â”œâ”€â”€ ğŸ§ª test_setup.py            # Environment verification
â”‚   â””â”€â”€ ğŸ“‚ model_checkpoints/       # Trained models
â”‚       â”œâ”€â”€ best_model.pt
â”‚       â”œâ”€â”€ continued_best_model.pt
â”‚       â”œâ”€â”€ training_curves.png
â”‚       â”œâ”€â”€ train_split.csv
â”‚       â””â”€â”€ val_split.csv
```

## ğŸ“š Dependencies

### Core ML Libraries
```python
# Deep Learning Framework
torch==2.0.1+cu118              # PyTorch with CUDA support
torchvision==0.15.2+cu118       # Computer vision utilities
torch-audio==2.0.2+cu118        # Audio processing (dependency)

# Transformer Models
transformers==4.30.2            # Hugging Face transformers
tokenizers==0.13.3              # Fast tokenization

# Computer Vision
timm==0.9.2                     # PyTorch Image Models
albumentations==1.3.1           # Advanced image augmentations
opencv-python==4.8.0.74         # Computer vision operations

# Data Processing
pandas==2.0.3                   # Data manipulation
numpy==1.24.3                   # Numerical computing
scikit-learn==1.3.0             # Machine learning utilities
```

### Utility Libraries
```python
# Image Processing
Pillow==10.0.0                  # Python Imaging Library
requests==2.31.0                # HTTP library for downloads

# Visualization & Logging
matplotlib==3.7.1               # Plotting library
seaborn==0.12.2                 # Statistical visualization
tqdm==4.65.0                    # Progress bars
logging                         # Built-in logging (Python std)

# System & Performance
psutil==5.9.5                   # System monitoring
memory-profiler==0.61.0         # Memory usage tracking
```

### Development Tools
```python
# Code Quality
black==23.7.0                   # Code formatting
flake8==6.0.0                   # Linting
pytest==7.4.0                   # Testing framework

# Jupyter Notebook Support
jupyter==1.0.0                  # Jupyter ecosystem
ipykernel==6.25.0              # Jupyter kernel
notebook==7.0.0                 # Jupyter notebook interface
```

## ğŸ† Key Achievements

### Technical Innovations
âœ… **Multimodal Architecture**: Successfully combined text and image features using cross-attention  
âœ… **Memory Optimization**: Efficient training on consumer-grade GPU (RTX 3050)  
âœ… **Robust Data Pipeline**: Handles image download failures and text processing edge cases  
âœ… **Production Ready**: Comprehensive error handling, logging, and validation  
âœ… **Ensemble Methods**: Multiple model combination for improved performance  

### Performance Highlights
ğŸ¯ **SMAPE Score**: Achieved 48% on validation set  
âš¡ **Training Speed**: Optimized for 6GB VRAM with mixed precision  
ğŸ”„ **Scalability**: Handles 75k sample datasets efficiently  
ğŸ’¾ **Memory Efficient**: Smart caching and garbage collection  
## ğŸ™ Acknowledgments

- **Hugging Face**: For the excellent transformers library
- **PyTorch Team**: For the deep learning framework
- **EfficientNet Authors**: For the efficient computer vision architecture
- **Competition Organizers**: For providing the challenging dataset and problem statement

---